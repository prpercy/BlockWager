{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Data Scraping #\n",
    "\n",
    "In this first step, we scrape Bundesliga (BuLi) data from a popular German sports website. Please understand that due to legal issues I have removed any URLs linking to the website in this Notebook. However, I hope you still understand the general procedure. We capture data starting from season 2013/2014, since it is the first season that includes statistics for distance covered by players during the game. The latest (finished) season we capture is season 2019/2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "import dateparser\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import warnings\n",
    "import requests\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define three methods:\n",
    "- **get_match_data:** Appends data for each game to the data nested list. Requires three input values: (1) the year in YY-format in which the captured season range starts (e.g. 13 to start with season 2013/2014), (2) the year in YY-format in which the final captured season range ends (e.g. 20 to capture season 2019/2020), and (3) the number of matchdays per season (for BuLi = 34 matchdays).\n",
    "- **get_links_matchday:** Returns URLs to all game's statistic pages of a matchday. Requires two input values: (1) the season in the format YY/YY and (2) matchday for which links to each game statistic URL should be provided.\n",
    "- **get_game_stats:** Returns game statistics for a single match. Requires three input values: (1) the URL to the statistics page, (2) the season in the format YY/YY and (2) the matchday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [] #nested list where all data is stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match_data(start_year, end_year, match_day):\n",
    "    season = str(start_year) + '-' + str(end_year)\n",
    "    links = get_links_matchday(season, match_day)\n",
    "    for link in links:\n",
    "        game_stats = get_game_stats(link, season, match_day)\n",
    "        data.append(game_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links_matchday(season, match_day):\n",
    "    URL = 'https://www.website_removed_due_to_legal_issues.de/bundesliga/spieltag/20' + season + '/' + str(match_day)\n",
    "    page = requests.get(URL)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    results = soup.findAll('a', {'class': 'kick__v100-scoreBoard kick__v100-scoreBoard--standard'})\n",
    "    links = []\n",
    "    for elem in results:\n",
    "        link = elem.get('href')\n",
    "        link_spieldaten = link.replace(\"analyse\",\"spieldaten\")\n",
    "        URL = 'https://www.website_removed_due_to_legal_issues.de/'+ link_spieldaten\n",
    "        links.append(URL)\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_game_stats(URL, season, match_day):\n",
    "    page = requests.get(URL)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    stats = []\n",
    "    stats.append(season)\n",
    "    stats.append(match_day)\n",
    "    teams = soup.findAll('div', {'class': 'kick__v100-gameCell__team__name'})\n",
    "    stats.append(teams[0].text)\n",
    "    stats.append(teams[1].text)\n",
    "    score = soup.findAll('div', {'class': 'kick__v100-scoreBoard__scoreHolder__score'})\n",
    "    for s,goal in enumerate(score):\n",
    "        stats.append(score[s].text)\n",
    "    stats_home = soup.findAll('div', {'class': 'kick__stats-bar__value kick__stats-bar__value--opponent1'})\n",
    "    stats_away = soup.findAll('div', {'class': 'kick__stats-bar__value kick__stats-bar__value--opponent2'})\n",
    "    for i in range(1,13,1):\n",
    "        stats.append(stats_home[i].text)\n",
    "        stats.append(stats_away[i].text)\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the actual scraping takes place, which will take approximately 45 minutes (for 8 seasons)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_season = 14\n",
    "end_season = 21\n",
    "\n",
    "for season in tqdm(range(start_season,end_season,1)):\n",
    "    for matchday in tqdm(range(1,35,1)):\n",
    "        get_match_data(season-1,season,matchday)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a data frame, in which we will store our scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.DataFrame(data,columns=['season',\n",
    "'matchday',\n",
    "'h_team',\n",
    "'a_team',\n",
    "'h_goals',\n",
    "'a_goals',\n",
    "'h_ht_goals',\n",
    "'a_ht_goals',\n",
    "'h_shots_on_goal',\n",
    "'a_shots_on_goal',\n",
    "'h_distance',\n",
    "'a_distance',\n",
    "'h_total_passes',\n",
    "'a_total_passes',\n",
    "'h_success_passes',\n",
    "'a_success_passes',\n",
    "'h_failed_passes',\n",
    "'a_failed_passes',\n",
    "'h_pass_ratio',\n",
    "'a_pass_ratio',\n",
    "'h_possesion',\n",
    "'a_possesion',\n",
    "'h_tackle_ratio',\n",
    "'a_tackle_ratio',\n",
    "'h_fouls',\n",
    "'a_fouls',\n",
    "'h_got_fouled',\n",
    "'a_got_fouled',\n",
    "'h_offside',\n",
    "'a_offside',\n",
    "'h_corners',\n",
    "'a_corners'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, we store our data in csv format for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.to_csv('./data/data_BuLi_13_20.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
