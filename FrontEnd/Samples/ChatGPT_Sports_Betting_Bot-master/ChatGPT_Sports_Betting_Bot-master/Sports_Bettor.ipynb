{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWnXvIaEybeu",
        "outputId": "4ec10dfa-aef5-443f-f24f-2c928d9c51d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successful Bootstrap!!!\n"
          ]
        }
      ],
      "source": [
        "#Remove Preexisting Files\n",
        "! rm -rf NBA-Machine-Learning-Sports-Betting\n",
        "! rm -rf *\n",
        "\n",
        "#Bootstrap Files\n",
        "! git clone https://github.com/kyleskom/NBA-Machine-Learning-Sports-Betting.git\n",
        "! mv -v ./NBA-Machine-Learning-Sports-Betting/* .\n",
        "! pip3 install -r requirements.txt\n",
        "\n",
        "#Clear Bootstrap Logs\n",
        "from IPython.display import clear_output \n",
        "clear_output()\n",
        "\n",
        "print(\"Successful Bootstrap!!!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python3 main.py -xgb -odds=fanduel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCw0Ed3Uyxr7",
        "outputId": "ac6aecb1-f810-45d0-9b79-dcd332ff4905"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
            "2023-01-17 22:49:54.643441: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2023-01-17 22:49:54.643551: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ce34f96c0d02): /proc/driver/nvidia/version does not exist\n",
            "2023-01-17 22:49:54.643953: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
            "------------------fanduel odds data------------------\n",
            "Toronto Raptors (106) @ Milwaukee Bucks (-124)\n",
            "Brooklyn Nets (-178) @ San Antonio Spurs (150)\n",
            "Portland Trail Blazers (194) @ Denver Nuggets (-235)\n",
            "Philadelphia 76ers (108) @ LA Clippers (-126)\n",
            "---------------XGBoost Model Predictions---------------\n",
            "\u001b[32mMilwaukee Bucks\u001b[0m\u001b[36m (76.7%)\u001b[0m vs \u001b[31mToronto Raptors\u001b[0m: \u001b[35mUNDER \u001b[0m222\u001b[0m\u001b[36m (55.1%)\u001b[0m\n",
            "\u001b[31mSan Antonio Spurs\u001b[0m vs \u001b[32mBrooklyn Nets\u001b[0m\u001b[36m (79.7%)\u001b[0m: \u001b[35mUNDER \u001b[0m229.5\u001b[0m\u001b[36m (56.8%)\u001b[0m\n",
            "\u001b[32mDenver Nuggets\u001b[0m\u001b[36m (77.7%)\u001b[0m vs \u001b[31mPortland Trail Blazers\u001b[0m: \u001b[35mUNDER \u001b[0m237\u001b[0m\u001b[36m (79.1%)\u001b[0m\n",
            "\u001b[31mLA Clippers\u001b[0m vs \u001b[32mPhiladelphia 76ers\u001b[0m\u001b[36m (58.7%)\u001b[0m: \u001b[35mUNDER \u001b[0m223\u001b[0m\u001b[36m (58.1%)\u001b[0m\n",
            "--------------------Expected Value---------------------\n",
            "Milwaukee Bucks EV: \u001b[32m38.61\u001b[0m\n",
            "Toronto Raptors EV: \u001b[31m-52.07\u001b[0m\n",
            "San Antonio Spurs EV: \u001b[31m-49.2\u001b[0m\n",
            "Brooklyn Nets EV: \u001b[32m24.45\u001b[0m\n",
            "Denver Nuggets EV: \u001b[32m10.76\u001b[0m\n",
            "Portland Trail Blazers EV: \u001b[31m-34.44\u001b[0m\n",
            "LA Clippers EV: \u001b[31m-25.9\u001b[0m\n",
            "Philadelphia 76ers EV: \u001b[32m22.07\u001b[0m\n",
            "-------------------------------------------------------\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##TODO"
      ],
      "metadata": {
        "id": "pSwcdROf6kvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Add Twitter Sentiment Analysis\n",
        "import tweepy\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Authenticate with Twitter API\n",
        "consumer_key = 'eq9QvcZRupgT1iBdqEbnu9Wea'\n",
        "consumer_secret = 'cvbu9YAI5TcGXkuVk6mNB54cNjlAo3Pbr3NcXGb109XFI2PcHX'\n",
        "access_token = '2479063608-4cx5s5H6wIRXZJBcM19MbGSBBLPUCuY8K54UYNv'\n",
        "access_token_secret = 'vpGBGHEzBrxNp1JKIeWSE9c1n5WMACamAeDVTcNFj8j8k'\n",
        "\n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "\n",
        "api = tweepy.API(auth)\n",
        "\n",
        "# Search for tweets about the Warriors\n",
        "warriors_tweets = tweepy.Cursor(api.search, q='#Golden State Warriors').items(100)\n",
        "\n",
        "\n",
        "# Perform sentiment analysis on tweets\n",
        "positive_tweets = 0\n",
        "negative_tweets = 0\n",
        "neutral_tweets = 0\n",
        "\n",
        "for tweet in warriors_tweets:\n",
        "    analysis = TextBlob(tweet.text)\n",
        "    if analysis.sentiment.polarity > 0:\n",
        "        positive_tweets += 1\n",
        "    elif analysis.sentiment.polarity < 0:\n",
        "        negative_tweets += 1\n",
        "    else:\n",
        "        neutral_tweets += 1\n",
        "\n",
        "# Print results\n",
        "print(\"Positive tweets: \", positive_tweets)\n",
        "print(\"Negative tweets: \", negative_tweets)\n",
        "print(\"Neutral tweets: \", neutral_tweets)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrfkqL4m_2kX",
        "outputId": "ece0a7ce-635f-4d7d-a205-8c2048370ada"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive tweets:  20\n",
            "Negative tweets:  3\n",
            "Neutral tweets:  17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVtf0ahbC6eo",
        "outputId": "f2a7840d-9f6c-48e0-b503-43fb0ae72223"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.26.1.tar.gz (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 KB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from openai) (3.8.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai) (4.59.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.8/dist-packages (from openai) (2.25.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (1.24.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (2.1.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->openai) (1.8.2)\n",
            "Building wheels for collected packages: openai\n",
            "  Building wheel for openai (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.26.1-py3-none-any.whl size=67316 sha256=729da3a688c20f73b776a229c5a6ad00c1ce250cf5a62a2ec509ed6c2b88f2b0\n",
            "  Stored in directory: /root/.cache/pip/wheels/2f/9c/55/95d3609ccfc463eeffb96d50c756f1f1899453b85e92021a0a\n",
            "Successfully built openai\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.26.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Add GPT Explanation\n",
        "\n",
        "\n",
        "# Import the OpenAI library\n",
        "import openai\n",
        "\n",
        "# Set the API key\n",
        "openai.api_key = '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'\n",
        "\n",
        "# Define the text to summarize\n",
        "text = \"------------------fanduel odds data------------------Toronto Raptors (106) @ Milwaukee Bucks (-124)Brooklyn Nets (-178) @ San Antonio Spurs (150)Portland Trail Blazers (194) @ Denver Nuggets (-235)Philadelphia 76ers (108) @ LA Clippers (-126)---------------XGBoost Model Predictions---------------Milwaukee Bucks (76.7%) vs Toronto Raptors: UNDER 222 (55.1%)San Antonio Spurs vs Brooklyn Nets (79.7%): UNDER 229.5 (56.8%)Denver Nuggets (77.7%) vs Portland Trail Blazers: UNDER 237 (79.1%)LA Clippers vs Philadelphia 76ers (58.7%): UNDER 223 (58.1%)--------------------Expected Value---------------------Milwaukee Bucks EV: 38.61Toronto Raptors EV: -52.07San Antonio Spurs EV: -49.2Brooklyn Nets EV: 24.45Denver Nuggets EV: 10.76Portland Trail Blazers EV: -34.44LA Clippers EV: -25.9Philadelphia 76ers EV: 22.07\"\n",
        "\n",
        "# Use the OpenAI API to summarize the text\n",
        "response = openai.Completion.create(\n",
        "    engine=\"text-davinci-002\",\n",
        "    prompt=(f\"summarize this text: {text}\"),\n",
        "    max_tokens=100\n",
        ")\n",
        "\n",
        "# Print the summary\n",
        "print(response[\"choices\"][0][\"text\"])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpzoF5AJCV6G",
        "outputId": "b891ea1e-bbb7-49f3-940e-80d550b3fcad"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "The Fanduel odds data predicts that the Milwaukee Bucks will beat the Toronto Raptors, the Brooklyn Nets will beat the San Antonio Spurs, the Denver Nuggets will beat the Portland Trail Blazers, and the LA Clippers will beat the Philadelphia 76ers. The XGBoost Model Predictions agree with these predictions. The Milwaukee Bucks have an expected value of 38.61, while the Toronto Raptors have an expected value of -52.07. The San Antonio Spurs have an expected value of -49\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##1 Make Bet from API \n",
        "\n"
      ],
      "metadata": {
        "id": "7BI3cUhlEMki"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}